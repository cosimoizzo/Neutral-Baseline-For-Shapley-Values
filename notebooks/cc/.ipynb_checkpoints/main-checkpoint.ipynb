{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "parent_dir = os.path.dirname(parent_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from explain.baseline_quantile import NeutralFairBaseline\n",
    "from explain.other_baselines import maximum_distance_bs\n",
    "from explain.other_baselines import p_data_bs\n",
    "from explain.sampling_shapley_mod import shapley_sampling\n",
    "from explain.sparse_mlp import get_sparse_mlp\n",
    "from explain.mlp import validate_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "samples = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30001, 24)\n",
      "Dataset:\n",
      "(29351, 24)\n",
      "Training set:  240  ( 115.0 )\n",
      "Testing set:  60  ( 35.0 )\n",
      "n features:  23\n"
     ]
    }
   ],
   "source": [
    "# Load CSV from URL using NumPy\n",
    "url = \"https://raw.githubusercontent.com/meauxt/credit-card-default/master/credit_cards_dataset.csv\"\n",
    "names = ['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
    "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
    "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
    "       'Default']\n",
    "df = pd.read_csv(url, names=names)\n",
    "df = df.drop(['ID'], axis = 1)\n",
    "names = names[1:np.size(names,0)]\n",
    "print(df.shape)\n",
    "\n",
    "# Convert to numeric\n",
    "for column in df:\n",
    "    df[column] = pd.to_numeric(df[column],errors='coerce')\n",
    "df = df.dropna()\n",
    "\n",
    "# rescale sex (sex : male = 0 , female = 1)\n",
    "df['SEX'][df['SEX']==1]=0\n",
    "df['SEX'][df['SEX']==2]=1\n",
    "\n",
    "# rescale marital status (married = 0, single = 1) after dropping 'others'\n",
    "df['MARRIAGE'][df['MARRIAGE']==1]=0\n",
    "df['MARRIAGE'][df['MARRIAGE']==2]=1\n",
    "df.drop(df[df['MARRIAGE']==3].index , inplace=True)\n",
    "\n",
    "# remove unknown from education\n",
    "df.drop(df[df['EDUCATION']==5].index, inplace=True)\n",
    "df.drop(df[df['EDUCATION']==6].index, inplace=True)\n",
    "print(\"Dataset:\")\n",
    "print(df.shape)\n",
    "\n",
    "# Convert in log PAY_AMT\n",
    "pay_atm_vars = ['PAY_AMT1','PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "for j in pay_atm_vars:\n",
    "    # set 0 to min\n",
    "    df[j][df[j]==0] = np.min(df[j][df[j]!=0])\n",
    "    # take log\n",
    "    df[j] = np.log(df[j])\n",
    "    \n",
    "# balanced subsampling\n",
    "index_sample = np.random.choice(df[df['Default']==1].index.values, size=samples // 2, replace=False)\n",
    "index_sample = np.hstack((np.random.choice(df[df['Default']==0].index.values, size=samples // 2, replace=False), index_sample))\n",
    "np.random.shuffle(index_sample)\n",
    "df = df.loc[index_sample]\n",
    "\n",
    "arr_df = df.values\n",
    "all_keys = df.keys()\n",
    "\n",
    "# Scale all data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(arr_df)\n",
    "arr_df = scaler.transform(arr_df)\n",
    "outcome = np.asarray(arr_df[:, -1])\n",
    "data = np.asarray(arr_df[:, :-1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, outcome, test_size=0.2, random_state=seed)\n",
    "n_vars = x_test.shape[1]\n",
    "n_out_of_sample = x_test.shape[0]\n",
    "print(\"Training set: \", x_train.shape[0], \" (\", np.sum(y_train), \")\") \n",
    "print(\"Testing set: \", n_out_of_sample, \" (\", np.sum(y_test), \")\") \n",
    "print('n features: ', n_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Best Model and Compute Performance on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b610166871c4ebcaadec53ff5cf562d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: \n",
      "((9, 'sigmoid'), (1, 'sigmoid'))\n",
      "Test set results: \n",
      "ROC AUC:  0.7805714285714286\n",
      "AVG PRE:  0.864737020111747\n"
     ]
    }
   ],
   "source": [
    "# Params for validation\n",
    "runs = 300\n",
    "hidden_layers = range(0, 6)\n",
    "nodes_hidden_layers = range(1, 11, 1)\n",
    "\n",
    "# Validate\n",
    "model, conf, performance = validate_mlp(x_train, y_train, runs, hidden_layers, nodes_hidden_layers)\n",
    "\n",
    "# Get Predictions\n",
    "y_hat_train = model.predict(x_train)\n",
    "y_hat_test = model.predict(x_test)\n",
    "roc_auc = roc_auc_score(np.array(y_test), y_hat_test)\n",
    "ave_pre = average_precision_score(np.array(y_test), y_hat_test)\n",
    "\n",
    "print('Best model: ')\n",
    "print(conf)\n",
    "print('Test set results: ')\n",
    "print(\"ROC AUC: \", roc_auc)\n",
    "print(\"AVG PRE: \", ave_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Feature Attributions using different Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runs_sh_sampling = 2**7\n",
    "\n",
    "# Get weights and biases and store them in a list\n",
    "ws = []\n",
    "bs = []\n",
    "for layer in model.layers:\n",
    "    ws.append(layer.get_weights()[0])\n",
    "    bs.append(layer.get_weights()[1])\n",
    "\n",
    "ls = []\n",
    "for _, activation in conf:\n",
    "    ls.append(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9169c238affc45df92f56a1e4f702a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9eac39b1a9430394d92d46b02a9d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 5h 54min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "zero_reference = np.zeros_like(x_test)[0, :]\n",
    "a_zero = np.array([shapley_sampling(model,\n",
    "                           x_test[i],\n",
    "                           y_hat_test[i],\n",
    "                           runs = runs_sh_sampling,\n",
    "                           baseline = zero_reference) for i in tqdm(range(x_test.shape[0]))])\n",
    "# training data\n",
    "a_zero_train = np.array([shapley_sampling(model,\n",
    "                           x_train[i],\n",
    "                           y_hat_train[i],\n",
    "                           runs = runs_sh_sampling,\n",
    "                           baseline = zero_reference) for i in tqdm(range(x_train.shape[0]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e71e6cc1b846bca803ae5d2b6055a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af94880139ac42d4933b3b99f7e1f0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 5h 41min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "average_reference = np.mean(x_train, 0)\n",
    "a_average = np.array([shapley_sampling(model,\n",
    "                              x_test[i],\n",
    "                              y_hat_test[i],\n",
    "                              runs = runs_sh_sampling,\n",
    "                              baseline = average_reference) for i in tqdm(range(x_test.shape[0]))])\n",
    "# training data\n",
    "a_average_train = np.array([shapley_sampling(model,\n",
    "                              x_train[i],\n",
    "                              y_hat_train[i],\n",
    "                              runs = runs_sh_sampling,\n",
    "                              baseline = average_reference) for i in tqdm(range(x_train.shape[0]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neutral (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction at the reference point is:  [[0.5004683]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262d91225ebe443eab771e976f829c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfc4e52b6964c52b9cd32eb6b3cfa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 6h 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Find baseline\n",
    "nf_bas = NeutralFairBaseline()\n",
    "reference, errors_list = nf_bas.search_baseline_mlp(ws, bs, ls, np.array(x_train))\n",
    "# Get Sparse Model\n",
    "model_sparse = get_sparse_mlp(ws, bs, ls, reference)\n",
    "# Apply Shapley\n",
    "a_neutral_05 = np.array([shapley_sampling(model_sparse,\n",
    "                                 x_test[i],\n",
    "                                 y_hat_test[i],\n",
    "                                 runs = runs_sh_sampling,\n",
    "                                 baseline = reference) for i in tqdm(range(x_test.shape[0]))])\n",
    "# training data\n",
    "a_neutral_05_train = np.array([shapley_sampling(model_sparse,\n",
    "                                 x_train[i],\n",
    "                                 y_hat_train[i],\n",
    "                                 runs = runs_sh_sampling,\n",
    "                                 baseline = reference) for i in tqdm(range(x_train.shape[0]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0964c5e379fc4684a50dec57af478786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d24301e17a149109c9edbd5d0e7df87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 5h 53min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "maxdist_references = np.zeros_like(x_test)\n",
    "for i in range(x_test.shape[0]):\n",
    "    maxdist_references[i] = maximum_distance_bs(x_train, x_test[i])\n",
    "\n",
    "maxdist_references_train = np.zeros_like(x_train)\n",
    "for i in range(x_train.shape[0]):\n",
    "    maxdist_references_train[i] = maximum_distance_bs(x_train, x_train[i])\n",
    "\n",
    "a_maxdist = np.zeros_like(x_test)\n",
    "for i in tqdm(range(x_test.shape[0])):\n",
    "    a_maxdist[i] = shapley_sampling(model,\n",
    "                                    x_test[i],\n",
    "                                    y_hat_test[i],\n",
    "                                    runs = runs_sh_sampling,\n",
    "                                    baseline = maxdist_references[i])\n",
    "# training data\n",
    "a_maxdist_train = np.zeros_like(x_train)\n",
    "for i in tqdm(range(x_train.shape[0])):\n",
    "    a_maxdist_train[i] = shapley_sampling(model,\n",
    "                                    x_train[i],\n",
    "                                    y_hat_train[i],\n",
    "                                    runs = runs_sh_sampling,\n",
    "                                    baseline = maxdist_references_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3807bfaaefd44c23b40c65b25540a656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa62ae7d52844504a5ce94861eae49e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 2d 12h 33min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_draws = 10\n",
    "pdata_references = p_data_bs(x_train, seed = 1, n_draws = n_draws)\n",
    "\n",
    "a_pdata = np.zeros_like(x_test)\n",
    "def comp_a_pdata(draw):\n",
    "    return np.array([shapley_sampling(model,\n",
    "                                      x_test[i],\n",
    "                                      y_hat_test[i],\n",
    "                                      runs = runs_sh_sampling,\n",
    "                                      baseline = pdata_references[draw]) for i in range(x_test.shape[0])])\n",
    "for draw in tqdm(range(n_draws)):\n",
    "    a_pdata += comp_a_pdata(draw)\n",
    "a_pdata /= n_draws\n",
    "\n",
    "\n",
    "a_pdata_train = np.zeros_like(x_train)\n",
    "def comp_a_pdata(draw):\n",
    "    return np.array([shapley_sampling(model,\n",
    "                                      x_train[i],\n",
    "                                      y_hat_train[i],\n",
    "                                      runs = runs_sh_sampling,\n",
    "                                      baseline = pdata_references[draw]) for i in range(x_train.shape[0])])\n",
    "for draw in tqdm(range(n_draws)):\n",
    "    a_pdata_train += comp_a_pdata(draw)\n",
    "a_pdata_train /= n_draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "# pickle model\n",
    "with open(\"conf.pickle\", \"wb\") as f:\n",
    "    pickle.dump(conf, f)\n",
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pickle references \n",
    "with open('zero_reference.npy', 'wb') as f:\n",
    "    np.save(f, zero_reference)\n",
    "with open('average_reference.npy', 'wb') as f:\n",
    "    np.save(f, average_reference)\n",
    "with open('reference.npy', 'wb') as f:\n",
    "    np.save(f, reference)\n",
    "with open('maxdist_references.npy', 'wb') as f:\n",
    "    np.save(f, maxdist_references)\n",
    "    np.save(f, maxdist_references_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pickle attributions \n",
    "with open('a_zero.npy', 'wb') as f:\n",
    "    np.save(f, a_zero)\n",
    "    np.save(f, a_zero_train)\n",
    "with open('a_average.npy', 'wb') as f:\n",
    "    np.save(f, a_average)\n",
    "    np.save(f, a_average_train)\n",
    "with open('a_neutral_05.npy', 'wb') as f:\n",
    "    np.save(f, a_neutral_05)\n",
    "    np.save(f, a_neutral_05_train)\n",
    "with open('a_maxdist.npy', 'wb') as f:\n",
    "    np.save(f, a_maxdist)\n",
    "    np.save(f, a_maxdist_train)\n",
    "with open('a_pdata.npy', 'wb') as f:\n",
    "    np.save(f, a_pdata)\n",
    "    np.save(f, a_pdata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
