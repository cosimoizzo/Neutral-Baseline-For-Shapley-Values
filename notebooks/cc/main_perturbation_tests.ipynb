{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "parent_dir = os.path.dirname(parent_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from explain.eval import local_analysis, local_roar\n",
    "from explain.sparse_mlp import get_sparse_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "samples = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV from URL using NumPy\n",
    "url = \"https://raw.githubusercontent.com/meauxt/credit-card-default/master/credit_cards_dataset.csv\"\n",
    "names = ['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
    "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
    "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
    "       'Default']\n",
    "df = pd.read_csv(url, names=names)\n",
    "df = df.drop(['ID'], axis = 1)\n",
    "names = names[1:np.size(names,0)]\n",
    "print(df.shape)\n",
    "\n",
    "# Convert to numeric\n",
    "for column in df:\n",
    "    df[column] = pd.to_numeric(df[column],errors='coerce')\n",
    "df = df.dropna()\n",
    "\n",
    "# rescale sex (sex : male = 0 , female = 1)\n",
    "df['SEX'][df['SEX']==1]=0\n",
    "df['SEX'][df['SEX']==2]=1\n",
    "\n",
    "# rescale marital status (married = 0, single = 1) after dropping 'others'\n",
    "df['MARRIAGE'][df['MARRIAGE']==1]=0\n",
    "df['MARRIAGE'][df['MARRIAGE']==2]=1\n",
    "df.drop(df[df['MARRIAGE']==3].index , inplace=True)\n",
    "\n",
    "# remove unknown from education\n",
    "df.drop(df[df['EDUCATION']==5].index, inplace=True)\n",
    "df.drop(df[df['EDUCATION']==6].index, inplace=True)\n",
    "print(\"Dataset:\")\n",
    "print(df.shape)\n",
    "\n",
    "# Convert in log PAY_AMT\n",
    "pay_atm_vars = ['PAY_AMT1','PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "for j in pay_atm_vars:\n",
    "    # set 0 to min\n",
    "    df[j][df[j]==0] = np.min(df[j][df[j]!=0])\n",
    "    # take log\n",
    "    df[j] = np.log(df[j])\n",
    "    \n",
    "# balanced subsampling\n",
    "index_sample = np.random.choice(df[df['Default']==1].index.values, size=samples // 2, replace=False)\n",
    "index_sample = np.hstack((np.random.choice(df[df['Default']==0].index.values, size=samples // 2, replace=False), index_sample))\n",
    "np.random.shuffle(index_sample)\n",
    "df = df.loc[index_sample]\n",
    "\n",
    "arr_df = df.values\n",
    "all_keys = df.keys()\n",
    "\n",
    "# Scale all data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(arr_df)\n",
    "arr_df = scaler.transform(arr_df)\n",
    "outcome = np.asarray(arr_df[:, -1])\n",
    "data = np.asarray(arr_df[:, :-1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, outcome, test_size=0.2, random_state=seed)\n",
    "n_vars = x_test.shape[1]\n",
    "n_out_of_sample = x_test.shape[0]\n",
    "print(\"Training set: \", x_train.shape[0], \" (\", np.sum(y_train), \")\") \n",
    "print(\"Testing set: \", n_out_of_sample, \" (\", np.sum(y_test), \")\") \n",
    "print('n features: ', n_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributions\n",
    "with open('a_zero.npy', 'rb') as f:\n",
    "        a_zero = np.load(f)\n",
    "        a_zero_train = np.load(f)\n",
    "with open('a_average.npy', 'rb') as f:\n",
    "        a_average = np.load(f)\n",
    "        a_average_train = np.load(f)\n",
    "with open('a_neutral_05.npy', 'rb') as f:\n",
    "        a_neutral_05 = np.load(f)\n",
    "        a_neutral_05_train = np.load(f)\n",
    "with open('a_maxdist.npy', 'rb') as f:\n",
    "        a_maxdist = np.load(f)\n",
    "        a_maxdist_train = np.load(f)\n",
    "with open('a_pdata.npy', 'rb') as f:\n",
    "        a_pdata = np.load(f)\n",
    "        a_pdata_train = np.load(f)\n",
    "# baselines\n",
    "with open('zero_reference.npy', 'rb') as f:\n",
    "    zero_reference = np.load(f)\n",
    "with open('average_reference.npy', 'rb') as f:\n",
    "    average_reference = np.load(f)\n",
    "with open('reference.npy', 'rb') as f:\n",
    "    reference = np.load(f)\n",
    "with open('maxdist_references.npy', 'rb') as f:\n",
    "    maxdist_references = np.load(f)\n",
    "    maxdist_references_train = np.load(f)\n",
    "# import model\n",
    "with open('conf.pickle', 'rb') as f:\n",
    "     conf = pickle.load(f)\n",
    "model = keras.models.load_model(\"model\")\n",
    "# build sparse model for neutral baselines\n",
    "# Get weights and biases and store them in a list\n",
    "ws = []\n",
    "bs = []\n",
    "for layer in model.layers:\n",
    "    ws.append(layer.get_weights()[0])\n",
    "    bs.append(layer.get_weights()[1])\n",
    "\n",
    "ls = []\n",
    "for _, activation in conf:\n",
    "    ls.append(activation)\n",
    "model_sparse = get_sparse_mlp(ws, bs, ls, reference)\n",
    "\n",
    "# Get Predictions\n",
    "y_hat_train = model.predict(x_train)\n",
    "y_hat_test = model.predict(x_test)\n",
    "roc_auc = roc_auc_score(np.array(y_test), y_hat_test)\n",
    "ave_pre = average_precision_score(np.array(y_test), y_hat_test)\n",
    "\n",
    "print('Best model: ')\n",
    "print(conf)\n",
    "print('Test set results: ')\n",
    "print(\"ROC AUC: \", roc_auc)\n",
    "print(\"AVG PRE: \", ave_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Analysis via Information Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_vars = a_zero.shape[1]\n",
    "cols = list(np.linspace(0, n_vars, n_vars+1).astype(int).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, abs_log_odds_a_zero = local_analysis(model, x_test, a_zero, zero_reference, asc=False)\n",
    "df_a_zero_abs = pd.DataFrame(abs_log_odds_a_zero, columns=cols)\n",
    "df_a_zero_abs.to_csv('./results/result_abs_zero.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, abs_log_odds_a_average = local_analysis(model, x_test, a_average, average_reference, asc=False)\n",
    "df_a_average_abs = pd.DataFrame(abs_log_odds_a_average, columns=cols)\n",
    "df_a_average_abs.to_csv('./results/result_abs_ave.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neutrality 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_base_x_feat = len(reference)//n_vars\n",
    "_, abs_log_odds_a_neutral = \\\n",
    "    local_analysis(model_sparse, x_test, a_neutral_05, reference, asc=False, n_base_x_feat = n_base_x_feat)\n",
    "df_a_neutral_abs = pd.DataFrame(abs_log_odds_a_neutral, columns=cols)\n",
    "df_a_neutral_abs.to_csv('./results/result_abs_neutral.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, abs_log_odds_a_maxdist = local_analysis(model, x_test, a_maxdist, maxdist_references, asc=False)\n",
    "df_a_maxdist_abs = pd.DataFrame(abs_log_odds_a_maxdist, columns=cols)\n",
    "df_a_maxdist_abs.to_csv('./results/result_abs_maxdist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, abs_log_odds_a_pdata = local_analysis(model, x_test, a_pdata, average_reference, asc=False)\n",
    "df_a_pdata_abs = pd.DataFrame(abs_log_odds_a_pdata, columns=cols)\n",
    "df_a_pdata_abs.to_csv('./results/result_abs_pdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Analysis via ROAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_train = 30\n",
    "# Zero\n",
    "abs_a_zero = np.abs(a_zero)\n",
    "abs_a_zero_train = np.abs(a_zero_train)\n",
    "delta_performance_a_zero = np.zeros(n_vars)\n",
    "delta_performance_a_zero[0] = ave_pre\n",
    "# Average\n",
    "abs_a_average = np.abs(a_average)\n",
    "abs_a_average_train = np.abs(a_average_train)\n",
    "delta_performance_a_average = np.zeros(n_vars)\n",
    "delta_performance_a_average[0] = ave_pre\n",
    "# Neutral\n",
    "abs_a_neutral = np.abs(a_neutral_05)\n",
    "abs_a_neutral_train = np.abs(a_neutral_05_train)\n",
    "delta_performance_a_neutral = np.zeros(n_vars)\n",
    "delta_performance_a_neutral[0] = ave_pre\n",
    "# Maximum Distance\n",
    "abs_a_maxdist = np.abs(a_maxdist)\n",
    "abs_a_maxdist_train = np.abs(a_maxdist_train)\n",
    "delta_performance_a_maxdist = np.zeros(n_vars)\n",
    "delta_performance_a_maxdist[0] = ave_pre\n",
    "# P_data\n",
    "abs_a_pdata = np.abs(a_pdata_train)\n",
    "abs_a_pdata_train = np.abs(a_pdata_train)\n",
    "delta_performance_a_pdata = np.zeros(n_vars)\n",
    "delta_performance_a_pdata[0] = ave_pre\n",
    "# random - uniform\n",
    "random_imp = np.random.random(abs_a_pdata.shape)\n",
    "random_imp_train = np.random.random(abs_a_pdata_train.shape)\n",
    "delta_performance_a_random = np.zeros(n_vars)\n",
    "delta_performance_a_random[0] = ave_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# roar on average\n",
    "for j in tqdm(range(n_vars - 1)):\n",
    "\n",
    "    delta_performance_a_zero[j + 1] = \\\n",
    "        local_roar(x_train, x_test,\n",
    "             y_train, y_test,\n",
    "             abs_a_zero_train, abs_a_zero,\n",
    "             conf, j, n_train = n_train, replace_with_train=[average_reference], replace_with_test=[average_reference])\n",
    "\n",
    "    delta_performance_a_average[j + 1] = \\\n",
    "        local_roar(x_train, x_test,\n",
    "             y_train, y_test,\n",
    "             abs_a_average_train, abs_a_average,\n",
    "             conf, j, n_train = n_train, replace_with_train=[average_reference], replace_with_test=[average_reference])\n",
    "\n",
    "    delta_performance_a_neutral[j + 1] = \\\n",
    "        local_roar(x_train, x_test,\n",
    "             y_train, y_test,\n",
    "             abs_a_neutral_train, abs_a_neutral,\n",
    "             conf, j, n_train = n_train, replace_with_train=[average_reference], replace_with_test=[average_reference])\n",
    "    \n",
    "    delta_performance_a_maxdist[j + 1] = \\\n",
    "        local_roar(x_train, x_test,\n",
    "             y_train, y_test,\n",
    "             abs_a_maxdist_train, abs_a_maxdist,\n",
    "             conf, j, n_train = n_train, replace_with_train=[average_reference], replace_with_test=[average_reference])\n",
    "\n",
    "    delta_performance_a_pdata[j + 1] = \\\n",
    "        local_roar(x_train, x_test,\n",
    "             y_train, y_test,\n",
    "             abs_a_pdata_train, abs_a_pdata,\n",
    "             conf, j, n_train = n_train, replace_with_train=[average_reference], replace_with_test=[average_reference])\n",
    "\n",
    "    delta_performance_a_random[j + 1] = \\\n",
    "        local_roar(x_train, x_test,\n",
    "             y_train, y_test,\n",
    "             random_imp_train, random_imp,\n",
    "             conf, j, n_train = n_train, replace_with_train=[average_reference], replace_with_test=[average_reference])\n",
    "\n",
    "results_df = pd.DataFrame({'zero _perf': delta_performance_a_zero, # 1 # sh on zeros\n",
    "                           'ave _perf': delta_performance_a_average, # 2 # sh on average\n",
    "                           'neutral _perf': delta_performance_a_neutral, # 3 # Neutral\n",
    "                           'max dist _perf': delta_performance_a_maxdist, # 4 # max dist\n",
    "                           'pdata _perf': delta_performance_a_pdata, # 5 # p data\n",
    "                           'random _perf': delta_performance_a_random # 6 # Random\n",
    "                           })\n",
    "\n",
    "results_df.to_csv('./results/results_ROAR.csv')"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
